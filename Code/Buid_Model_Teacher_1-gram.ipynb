{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x7LBfh0uLpup","colab":{"base_uri":"https://localhost:8080/"},"outputId":"864340fe-3e4c-4962-a114-6fbb25337c62","executionInfo":{"status":"ok","timestamp":1716178128511,"user_tz":-420,"elapsed":17318,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOc-mgrK5B_6"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import pickle as cPickle\n","import pandas as pd\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n","import sklearn.metrics\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.model_selection import KFold\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n","from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional\n","from keras import models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mt34EtLoLpup"},"outputs":[],"source":["data_teacher = \"/content/drive/MyDrive/KD2_Predict_ArapUbi/Data/Data for teacher/\"\n","path_model = \"/content/drive/MyDrive/KD2_Predict_ArapUbi/Model/\"\n","path_result = \"/content/drive/MyDrive/KD2_Predict_ArapUbi/Result/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUUYvlp8Lpup"},"outputs":[],"source":["def twoTupleDic3():\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        for j in AA_list_sort:\n","          for jj in AA_list_sort:\n","             AA_dict[i+j+jj] = numm\n","             numm += 1\n","    return AA_dict\n","def twoTupleDic2():\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        for j in AA_list_sort:\n","          AA_dict[i+j] = numm\n","          numm += 1\n","    return AA_dict\n","\n","def twoTupleDic1():\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        AA_dict[i] = numm\n","        numm += 1\n","    return AA_dict\n","def ProSentence(pro, K):\n","\tsentence = \"\"\n","\tlength = len(pro)\n","\tfor i in range(length - K + 1):\n","\t\tsentence += pro[i: i + K] + \" \"\n","    #delete extra space\n","\tsentence = sentence[0 : len(sentence) - 1]\n","\treturn sentence\n","k =1#1-gram\n","word_index1 = twoTupleDic1()\n","vocab_size = len(word_index1)\n","num_folds = 5\n","TIME_STEPS = 33\n","INPUT_SIZE = 300"]},{"cell_type":"markdown","metadata":{"id":"EyuTa72cLpur"},"source":["**Load data for teacher training**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TfIk7iwbLpur","colab":{"base_uri":"https://localhost:8080/"},"outputId":"919d9d72-c9be-48f3-b117-54760fb2f39f","executionInfo":{"status":"ok","timestamp":1716178133369,"user_tz":-420,"elapsed":601,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6746, 2)"]},"metadata":{},"execution_count":5}],"source":["# Load Traindata\n","file_train_teacher = \"train_data_3speaces_31.csv\"\n","df_train_teacher =pd.read_csv(data_teacher +file_train_teacher, delimiter= ',')\n","texts_train_teacher =[] #PTMsequend kmer\n","for i in df_train_teacher['Sequence']:\n","  temp = ProSentence(i,k) # Biểu diễn dữ liệu đầu vào thành token Kmer\n","  texts_train_teacher.append(temp)\n","df_train_teacher['k_mer'] =texts_train_teacher\n","train_sequences_teacher = []\n","for each in texts_train_teacher:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    train_sequences_teacher.append(each_index_list)\n","# Tokenizer train data\n","data_token_teacher = []\n","for i in df_train_teacher['k_mer']:\n","   data_token_teacher.append(i.split())\n","\n","# Len of the K_mer[1]\n","\n","MAX_SEQUENCE_LENGTH = len(data_token_teacher[1])\n","\n","Xtrain_teacher = pad_sequences(train_sequences_teacher, maxlen=MAX_SEQUENCE_LENGTH)\n","ytrain_teacher = np.array(df_train_teacher['Label'])\n","Xtrain_teacher.shape\n","ytrain_teacher = np.array(ytrain_teacher)\n","\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","ytrain_teacher = lb.fit_transform(ytrain_teacher)\n","ytrain_teacher = to_categorical(ytrain_teacher)\n","ytrain_teacher.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0BeJLTXLpus","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a16efe8e-3e38-4060-fd24-ba5bad3d1f9c","executionInfo":{"status":"ok","timestamp":1716178133931,"user_tz":-420,"elapsed":566,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1500, 2)"]},"metadata":{},"execution_count":6}],"source":["# load test data for teacher\n","file_test_teacher =\"test_data_3speaces_31.csv\"\n","df_test_teacher =pd.read_csv(data_teacher+file_test_teacher,delimiter= ',')\n","text_test_teacher =[] #PTMsequend kmer\n","for i in df_test_teacher['Sequence']:\n","  temp = ProSentence(i,k) # Biểu diễn dữ liệu đầu vào thành token Kmer\n","  text_test_teacher.append(temp)\n","df_test_teacher['k_mer'] =text_test_teacher\n","\n","test_sequences_teacher = []\n","for each in text_test_teacher:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    test_sequences_teacher.append(each_index_list)\n","\n","Xtest_teacher = pad_sequences(test_sequences_teacher, maxlen=MAX_SEQUENCE_LENGTH)\n","ytest_teacher = np.array(df_test_teacher['Label'])\n","Xtest_teacher.shape\n","ytest_teacher = np.array(ytest_teacher)\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","ytest_teacher= lb.fit_transform(ytest_teacher)\n","ytest_teacher = to_categorical(ytest_teacher)\n","ytest_teacher.shape"]},{"cell_type":"markdown","source":["**Define Teacher model**"],"metadata":{"id":"Hud3BNBGkcH_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o92YRtPh5Knd"},"outputs":[],"source":["\n","teacher = keras.Sequential(\n","    [\n","        layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True),\n","        #layers.Embedding(len(embedding_matrix), EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH_teacher,trainable=True),\n","        layers.Bidirectional(LSTM(units=32,batch_input_shape=(None,TIME_STEPS, INPUT_SIZE),return_sequences=True)),\n","        layers.Dropout(0.2),\n","        layers.Flatten(),\n","        layers.Dense(128),\n","        layers.Activation('relu'),\n","        layers.Dropout(0.2),\n","        layers.Dense(2),\n","        layers.Activation('softmax'),\n","    ],\n","    name=\"teacher\",\n",")\n","\n","teacher.compile(\n","    loss=keras.losses.CategoricalCrossentropy(),\n","    metrics=[\n","        \"categorical_accuracy\",\n","        \"AUC\",\n","\n","    ],\n","    optimizer=keras.optimizers.AdamW(learning_rate=0.0001),\n",")\n","checkpoint = EarlyStopping(monitor='val_loss',\n","            min_delta=0,\n","            patience=3,\n","            verbose=1, mode='auto')"]},{"cell_type":"markdown","source":["Teacher train"],"metadata":{"id":"jm_l7Hy3whr1"}},{"cell_type":"code","source":["# Train teacher and save model\n","teacher.fit(Xtrain_teacher, ytrain_teacher, batch_size=16, epochs=100,validation_data =(Xtest_teacher, ytest_teacher), shuffle = True,callbacks=[checkpoint],verbose=1)\n","teacher.save(path_result +\"teacher_KD2_1gram.h5\")"],"metadata":{"id":"xFWAtxft30Gh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716178446258,"user_tz":-420,"elapsed":38309,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}},"outputId":"2ed7c34c-8d13-486a-8153-c70b01798282"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","422/422 [==============================] - 8s 19ms/step - loss: 0.4076 - categorical_accuracy: 0.8217 - auc: 0.8973 - val_loss: 0.3843 - val_categorical_accuracy: 0.8400 - val_auc: 0.9101\n","Epoch 2/100\n","422/422 [==============================] - 8s 19ms/step - loss: 0.4011 - categorical_accuracy: 0.8257 - auc: 0.9002 - val_loss: 0.3770 - val_categorical_accuracy: 0.8420 - val_auc: 0.9131\n","Epoch 3/100\n","422/422 [==============================] - 7s 18ms/step - loss: 0.3947 - categorical_accuracy: 0.8318 - auc: 0.9034 - val_loss: 0.3869 - val_categorical_accuracy: 0.8427 - val_auc: 0.9085\n","Epoch 4/100\n","422/422 [==============================] - 8s 18ms/step - loss: 0.3861 - categorical_accuracy: 0.8352 - auc: 0.9082 - val_loss: 0.3774 - val_categorical_accuracy: 0.8413 - val_auc: 0.9128\n","Epoch 5/100\n","422/422 [==============================] - 7s 17ms/step - loss: 0.3815 - categorical_accuracy: 0.8375 - auc: 0.9104 - val_loss: 0.3815 - val_categorical_accuracy: 0.8513 - val_auc: 0.9112\n","Epoch 5: early stopping\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}