{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x7LBfh0uLpup","colab":{"base_uri":"https://localhost:8080/"},"outputId":"48c55d8f-33d2-4765-d0e6-e54a8a7f6c69","executionInfo":{"status":"ok","timestamp":1716179578445,"user_tz":-420,"elapsed":20123,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOc-mgrK5B_6"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import pickle as cPickle\n","import pandas as pd\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n","import sklearn.metrics\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.model_selection import KFold\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n","\n","from tensorflow.keras import Model\n","from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional\n","from keras import models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mt34EtLoLpup"},"outputs":[],"source":["data_student = \"/content/drive/MyDrive/KD2_Predict_ArapUbi/Data/Data for Student/\"\n","\n","path_model = \"/content/drive/MyDrive/KD2_Predict_ArapUbi/Model/\"\n","path_result = \"/content/drive/MyDrive/KD2_Predict_ArapUbi/Result/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUUYvlp8Lpup"},"outputs":[],"source":["\n","def twoTupleDic1():\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        AA_dict[i] = numm\n","        numm += 1\n","    return AA_dict\n","def ProSentence(pro, K):\n","\tsentence = \"\"\n","\tlength = len(pro)\n","\tfor i in range(length - K + 1):\n","\t\tsentence += pro[i: i + K] + \" \"\n","    #delete extra space\n","\tsentence = sentence[0 : len(sentence) - 1]\n","\treturn sentence\n","k =1#1-gram\n","word_index1 = twoTupleDic1()\n","vocab_size = len(word_index1)\n","num_folds = 5\n","TIME_STEPS = 33\n","INPUT_SIZE = 300"]},{"cell_type":"markdown","metadata":{"id":"EhO3XeaILput"},"source":["**Load data for Student training**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QeJNsISDLput","colab":{"base_uri":"https://localhost:8080/"},"outputId":"94abd804-6284-4c51-fe33-e829a570a9a3","executionInfo":{"status":"ok","timestamp":1716179583566,"user_tz":-420,"elapsed":1386,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3064, 2)"]},"metadata":{},"execution_count":5}],"source":["# Load Traindata\n","import pandas as pd\n","file_train_student = \"train_data_31_Arathailiana_1_1.csv\"\n","df_train_student =pd.read_csv(data_student+file_train_student, delimiter= ',')\n","\n","texts_train_student =[] #PTMsequend kmer\n","for i in df_train_student['Sequence']:\n","  temp = ProSentence(i,k)\n","  texts_train_student.append(temp)\n","df_train_student['k_mer'] =texts_train_student\n","train_sequences_student = []\n","for each in texts_train_student:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    train_sequences_student.append(each_index_list)\n","# Tokenizer train data\n","data_token_student = []\n","for i in df_train_student['k_mer']:\n","   data_token_student.append(i.split())\n","MAX_SEQUENCE_LENGTH = len(data_token_student[1])\n","\n","Xtrain_student = pad_sequences(train_sequences_student, maxlen=MAX_SEQUENCE_LENGTH)\n","ytrain_student = np.array(df_train_student['Label'])\n","ytrain_student = np.array(ytrain_student)\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","ytrain_student = lb.fit_transform(ytrain_student)\n","ytrain_student = to_categorical(ytrain_student)\n","ytrain_student.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkImwNniLput","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81b0ee03-739a-4727-ac34-d1bafd1f2f47","executionInfo":{"status":"ok","timestamp":1716179584700,"user_tz":-420,"elapsed":1137,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1022, 2)"]},"metadata":{},"execution_count":6}],"source":["# load test data for student\n","file_test_student =\"test_data_31_Arathailiana_1_1.csv\"\n","df_test_student =pd.read_csv(data_student+file_test_student,delimiter= ',')\n","text_test_student =[] #PTMsequend kmer\n","for i in df_test_student['Sequence']:\n","  temp = ProSentence(i,k)\n","  text_test_student.append(temp)\n","df_test_student['k_mer'] =text_test_student\n","\n","test_sequences_student = []\n","for each in text_test_student:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    test_sequences_student.append(each_index_list)\n","\n","Xtest_student = pad_sequences(test_sequences_student, maxlen=MAX_SEQUENCE_LENGTH)\n","ytest_student = np.array(df_test_student['Label'])\n","# perform one-hot encoding on the labels\n","ytest_student = np.array(ytest_student)\n","lb = LabelBinarizer()\n","ytest_student= lb.fit_transform(ytest_student)\n","ytest_student = to_categorical(ytest_student)\n","ytest_student.shape"]},{"cell_type":"markdown","source":["**Define Distillation Knowlege**"],"metadata":{"id":"Hud3BNBGkcH_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o92YRtPh5Knd"},"outputs":[],"source":["class Distiller(keras.Model):\n","    def __init__(self, student, teacher):\n","        super().__init__()\n","        self.teacher = teacher\n","        self.student = student\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","        student_loss_fn,\n","        distillation_loss_fn,\n","        alpha=0.1,\n","        temperature=3,\n","    ):\n","        \"\"\" Configure the distiller.\n","\n","        Args:\n","            optimizer: Keras optimizer for the student weights\n","            metrics: Keras metrics for evaluation\n","            student_loss_fn: Loss function of difference between student\n","                predictions and ground-truth\n","            distillation_loss_fn: Loss function of difference between soft\n","                student predictions and soft teacher predictions\n","            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n","            temperature: Temperature for softening probability distributions.\n","                Larger temperature gives softer distributions.\n","        \"\"\"\n","        super().compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","        self.alpha = alpha\n","        self.temperature = temperature\n","\n","    def train_step(self, data):\n","        # Unpack data\n","        x, y = data\n","\n","        # Forward pass of teacher\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            # Forward pass of student\n","            student_predictions = self.student(x, training=True)\n","\n","            # Compute losses\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","\n","            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n","            # The magnitudes of the gradients produced by the soft targets scale\n","            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n","            distillation_loss = (\n","                self.distillation_loss_fn(\n","                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n","                )\n","                * self.temperature**2\n","            )\n","\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n","\n","        # Compute gradients\n","        trainable_vars = self.student.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # Update the metrics configured in `compile()`.\n","        self.compiled_metrics.update_state(y, student_predictions)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update(\n","            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n","        )\n","        return results\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","\n","        # Compute predictions\n","        y_prediction = self.student(x, training=False)\n","\n","        # Calculate the loss\n","        student_loss = self.student_loss_fn(y, y_prediction)\n","\n","        # Update the metrics.\n","        self.compiled_metrics.update_state(y, y_prediction)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update({\"student_loss\": student_loss})\n","        return results\n","teacher = keras.Sequential(\n","    [\n","        layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True),\n","        #layers.Embedding(len(embedding_matrix), EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH_teacher,trainable=True),\n","        layers.Bidirectional(LSTM(units=32,batch_input_shape=(None,TIME_STEPS, INPUT_SIZE),return_sequences=True)),\n","        layers.Dropout(0.2),\n","        layers.Flatten(),\n","        layers.Dense(128),\n","        layers.Activation('relu'),\n","        layers.Dropout(0.2),\n","        layers.Dense(2),\n","        layers.Activation('softmax'),\n","    ],\n","    name=\"teacher\",\n",")\n","\n","teacher.compile(\n","    loss=keras.losses.CategoricalCrossentropy(),\n","    metrics=[\n","        \"categorical_accuracy\",\n","        \"AUC\",\n","\n","    ],\n","    optimizer=keras.optimizers.AdamW(learning_rate=0.0001),\n",")\n","student = keras.Sequential(\n","    [\n","        layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True),\n","        #layers.Embedding(len(embedding_matrix), EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH_student,trainable=True),\n","        layers.Bidirectional(LSTM(units=16,batch_input_shape=(None,TIME_STEPS, INPUT_SIZE),return_sequences=True)),\n","        layers.Dropout(0.2),\n","        layers.Flatten(),\n","        layers.Dense(128),\n","        layers.Activation('relu'),\n","        layers.Dropout(0.2),\n","        layers.Dense(2),\n","        layers.Activation('softmax'),\n","    ],\n","    name=\"student\",\n",")\n","student_scratch = keras.models.clone_model(student)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O336skmC67je"},"outputs":[],"source":["checkpoint = EarlyStopping(monitor='val_loss',\n","            min_delta=0,\n","            patience=3,\n","            verbose=1, mode='auto')\n","result_test =path_result +\"Result_KD2_1gram_id.txt\"\n"]},{"cell_type":"code","source":["# Independent test Knowlege distillation model\n","#Load model teacher for train student\n","teacher_model = models.load_model(path_model+'teacher_KD2_1gram.h5')\n","distiller = Distiller(student=student, teacher=teacher_model)\n","distiller.compile(\n","      student_loss_fn= keras.losses.CategoricalCrossentropy(from_logits=True),\n","      #student_loss_fn= keras.losses.BinaryCrossentropy(from_logits=True),\n","      optimizer=keras.optimizers.AdamW(learning_rate = 0.0001),\n","      metrics=[\n","              \"categorical_accuracy\",\n","              \"AUC\",\n","              ], # , f1\n","      distillation_loss_fn=keras.losses.KLDivergence(),\n","      alpha=0.1,\n","      temperature=10\n","      )\n","\n","history_KD = distiller.fit(Xtrain_student,ytrain_student, batch_size=16,epochs=50)#, validation_data =(Xtest_student, ytest_student), callbacks=[checkpoint],verbose=1)\n","result2 = distiller.evaluate(Xtest_student, ytest_student)#, validation_data=(X_test,Y_test), shuffle = True,callbacks=[checkpoint],verbose=1)\n","f = open(result_test, 'a+', encoding='UTF-8')\n","f.write(\"\\n Independent test  \\n \")\n","s = str(result2)\n","f.write(s)\n","f.close()\n","\n","ypred = student.predict(Xtest_student)\n","ypred =np.argmax(ypred,axis =1)\n","\n","ytest_true =  np.argmax(ytest_student,axis =1)\n","\n","result22 = confusion_matrix(ytest_true,ypred)\n","print(result22)\n","f = open(result_test, 'a+', encoding='UTF-8')\n","f.write(\"\\n confusion_matrix \\n \")\n","s = str(result22)\n","f.write(s)\n","f.close()\n"],"metadata":{"id":"s7qr8EjU3Wze","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d620a736-3b00-423a-fb30-42abb50baa1a","executionInfo":{"status":"ok","timestamp":1716179854117,"user_tz":-420,"elapsed":141678,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","192/192 [==============================] - 7s 15ms/step - categorical_accuracy: 0.7954 - auc: 0.8592 - student_loss: 0.4722 - distillation_loss: 0.0262\n","Epoch 2/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.7967 - auc: 0.8752 - student_loss: 0.4485 - distillation_loss: 0.0241\n","Epoch 3/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8107 - auc: 0.8928 - student_loss: 0.4237 - distillation_loss: 0.0213\n","Epoch 4/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8287 - auc: 0.9082 - student_loss: 0.3964 - distillation_loss: 0.0180\n","Epoch 5/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8420 - auc: 0.9169 - student_loss: 0.3721 - distillation_loss: 0.0154\n","Epoch 6/50\n","192/192 [==============================] - 3s 15ms/step - categorical_accuracy: 0.8499 - auc: 0.9231 - student_loss: 0.3580 - distillation_loss: 0.0141\n","Epoch 7/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8515 - auc: 0.9241 - student_loss: 0.3525 - distillation_loss: 0.0139\n","Epoch 8/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8587 - auc: 0.9293 - student_loss: 0.3419 - distillation_loss: 0.0133\n","Epoch 9/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8574 - auc: 0.9299 - student_loss: 0.3401 - distillation_loss: 0.0125\n","Epoch 10/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8584 - auc: 0.9322 - student_loss: 0.3328 - distillation_loss: 0.0124\n","Epoch 11/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8603 - auc: 0.9334 - student_loss: 0.3319 - distillation_loss: 0.0121\n","Epoch 12/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8652 - auc: 0.9354 - student_loss: 0.3262 - distillation_loss: 0.0116\n","Epoch 13/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8691 - auc: 0.9391 - student_loss: 0.3219 - distillation_loss: 0.0115\n","Epoch 14/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8681 - auc: 0.9380 - student_loss: 0.3211 - distillation_loss: 0.0118\n","Epoch 15/50\n","192/192 [==============================] - 3s 15ms/step - categorical_accuracy: 0.8678 - auc: 0.9378 - student_loss: 0.3236 - distillation_loss: 0.0116\n","Epoch 16/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8701 - auc: 0.9393 - student_loss: 0.3193 - distillation_loss: 0.0114\n","Epoch 17/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8688 - auc: 0.9412 - student_loss: 0.3175 - distillation_loss: 0.0110\n","Epoch 18/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8704 - auc: 0.9435 - student_loss: 0.3088 - distillation_loss: 0.0109\n","Epoch 19/50\n","192/192 [==============================] - 3s 15ms/step - categorical_accuracy: 0.8750 - auc: 0.9433 - student_loss: 0.3075 - distillation_loss: 0.0107\n","Epoch 20/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8779 - auc: 0.9454 - student_loss: 0.3035 - distillation_loss: 0.0106\n","Epoch 21/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8763 - auc: 0.9463 - student_loss: 0.3016 - distillation_loss: 0.0106\n","Epoch 22/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8757 - auc: 0.9463 - student_loss: 0.2998 - distillation_loss: 0.0103\n","Epoch 23/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8825 - auc: 0.9477 - student_loss: 0.2993 - distillation_loss: 0.0103\n","Epoch 24/50\n","192/192 [==============================] - 3s 15ms/step - categorical_accuracy: 0.8796 - auc: 0.9491 - student_loss: 0.2985 - distillation_loss: 0.0102\n","Epoch 25/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8796 - auc: 0.9489 - student_loss: 0.2937 - distillation_loss: 0.0100\n","Epoch 26/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8819 - auc: 0.9487 - student_loss: 0.2943 - distillation_loss: 0.0099\n","Epoch 27/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8802 - auc: 0.9511 - student_loss: 0.2884 - distillation_loss: 0.0100\n","Epoch 28/50\n","192/192 [==============================] - 3s 15ms/step - categorical_accuracy: 0.8805 - auc: 0.9506 - student_loss: 0.2915 - distillation_loss: 0.0096\n","Epoch 29/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8819 - auc: 0.9521 - student_loss: 0.2869 - distillation_loss: 0.0094\n","Epoch 30/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8877 - auc: 0.9530 - student_loss: 0.2833 - distillation_loss: 0.0092\n","Epoch 31/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8871 - auc: 0.9507 - student_loss: 0.2892 - distillation_loss: 0.0092\n","Epoch 32/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8894 - auc: 0.9550 - student_loss: 0.2787 - distillation_loss: 0.0097\n","Epoch 33/50\n","192/192 [==============================] - 3s 15ms/step - categorical_accuracy: 0.8858 - auc: 0.9542 - student_loss: 0.2825 - distillation_loss: 0.0094\n","Epoch 34/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8874 - auc: 0.9550 - student_loss: 0.2805 - distillation_loss: 0.0093\n","Epoch 35/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8887 - auc: 0.9552 - student_loss: 0.2780 - distillation_loss: 0.0091\n","Epoch 36/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8910 - auc: 0.9565 - student_loss: 0.2777 - distillation_loss: 0.0087\n","Epoch 37/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8900 - auc: 0.9548 - student_loss: 0.2815 - distillation_loss: 0.0086\n","Epoch 38/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8923 - auc: 0.9575 - student_loss: 0.2736 - distillation_loss: 0.0087\n","Epoch 39/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8864 - auc: 0.9574 - student_loss: 0.2733 - distillation_loss: 0.0087\n","Epoch 40/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8939 - auc: 0.9578 - student_loss: 0.2734 - distillation_loss: 0.0085\n","Epoch 41/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8936 - auc: 0.9588 - student_loss: 0.2713 - distillation_loss: 0.0084\n","Epoch 42/50\n","192/192 [==============================] - 3s 15ms/step - categorical_accuracy: 0.8887 - auc: 0.9592 - student_loss: 0.2704 - distillation_loss: 0.0085\n","Epoch 43/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8952 - auc: 0.9586 - student_loss: 0.2719 - distillation_loss: 0.0082\n","Epoch 44/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8965 - auc: 0.9602 - student_loss: 0.2656 - distillation_loss: 0.0082\n","Epoch 45/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8965 - auc: 0.9606 - student_loss: 0.2654 - distillation_loss: 0.0079\n","Epoch 46/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8952 - auc: 0.9604 - student_loss: 0.2669 - distillation_loss: 0.0081\n","Epoch 47/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.9011 - auc: 0.9618 - student_loss: 0.2622 - distillation_loss: 0.0079\n","Epoch 48/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8975 - auc: 0.9639 - student_loss: 0.2598 - distillation_loss: 0.0078\n","Epoch 49/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8982 - auc: 0.9617 - student_loss: 0.2606 - distillation_loss: 0.0079\n","Epoch 50/50\n","192/192 [==============================] - 3s 14ms/step - categorical_accuracy: 0.8936 - auc: 0.9622 - student_loss: 0.2649 - distillation_loss: 0.0075\n","32/32 [==============================] - 1s 6ms/step - categorical_accuracy: 0.8581 - auc: 0.9255 - student_loss: 0.3449\n","32/32 [==============================] - 1s 5ms/step\n","[[437  74]\n"," [ 71 440]]\n"]}]},{"cell_type":"code","source":["# save model Knowlege distillation\n","student.save(path_result +\"KD2_1gram.h5\")"],"metadata":{"id":"YX4Of-IMQxm4"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}